{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from dollarpy import Recognizer, Template, Point\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Function to get points from a video\n",
    "def getPoints(videoURL):\n",
    "    cap = cv2.VideoCapture(videoURL)\n",
    "    points = []\n",
    "\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results = hands.process(image)\n",
    "\n",
    "                if results.multi_hand_landmarks:\n",
    "                    for hand_landmarks in results.multi_hand_landmarks:\n",
    "                        for landmark in hand_landmarks.landmark:\n",
    "                            x, y = landmark.x, landmark.y\n",
    "                            if not (np.isnan(x) or np.isnan(y)):\n",
    "                                points.append(Point(x, y, stroke_id=0))\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    cap.release()\n",
    "    return points if points else []\n",
    "\n",
    "# Function to process multiple videos for a single gesture\n",
    "def getPointsForMultipleVideos(video_list, label):\n",
    "    templates = []\n",
    "    for video in video_list:\n",
    "        points = getPoints(video)\n",
    "        if points:\n",
    "            x_values = [p.x for p in points]\n",
    "            y_values = [p.y for p in points]\n",
    "            if max(x_values) - min(x_values) != 0 and max(y_values) - min(y_values) != 0:\n",
    "                templates.append(Template(label, points))\n",
    "    return templates\n",
    "\n",
    "# Function to train templates and save them\n",
    "def trainTemplates(save_path):\n",
    "    templates = []\n",
    "\n",
    "    # Define gestures and their videos\n",
    "    gesture_videos = {\n",
    "      \n",
    "        \"right\": [\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right1.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right2.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right3.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right4.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right5.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right6.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right7.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right8.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right9.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right10.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\right11.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\left\\right12.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\left\\right13.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\left\\right14.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\left\\right15.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\left\\right16.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\left\\right17.mp4\"\n",
    "        ],\n",
    "        \"left\": [\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left1.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left2.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left3.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left4.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left5.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left6.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left7.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left8.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left9.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left10.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left11.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left12.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\left13.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\right\\left14.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\right\\left15.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\right\\left16.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\right\\left17.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\right\\left18.mp4\",\n",
    "            r\"C:\\Users\\alie0\\Downloads\\Dataset\\Dataset\\right\\left19.mp4\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Train templates for each gesture\n",
    "    for label, videos in gesture_videos.items():\n",
    "        templates.extend(getPointsForMultipleVideos(videos, label))\n",
    "\n",
    "    # Save templates to disk\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(templates, f)\n",
    "    print(f\"Templates saved to {save_path}\")\n",
    "\n",
    "# Function to load templates from file\n",
    "def loadTemplates(save_path):\n",
    "    if os.path.exists(save_path):\n",
    "        with open(save_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return []\n",
    "\n",
    "# Function to get points from a single frame\n",
    "def getPointsFromFrame(frame):\n",
    "    points = []\n",
    "\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Process hand landmarks\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    x, y = landmark.x, landmark.y\n",
    "                    if not (np.isnan(x) or np.isnan(y)):\n",
    "                        points.append(Point(x, y, stroke_id=0))\n",
    "    return points\n",
    "\n",
    "# Main program\n",
    "template_file = \"gesture_templates2.pkl\"\n",
    "if not os.path.exists(template_file):\n",
    "    trainTemplates(template_file)\n",
    "\n",
    "templates = loadTemplates(template_file)\n",
    "\n",
    "# Initialize Recognizer with loaded templates\n",
    "recognizer = Recognizer(templates)\n",
    "\n",
    "# Use live camera feed to recognize gestures\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to capture frame from camera.\")\n",
    "            break\n",
    "\n",
    "        points = getPointsFromFrame(frame)\n",
    "        x_values = [p.x for p in points]\n",
    "        y_values = [p.y for p in points]\n",
    "\n",
    "        if points and (max(x_values) - min(x_values) != 0) and (max(y_values) - min(y_values) != 0):\n",
    "            result = recognizer.recognize(points)\n",
    "\n",
    "            if result:\n",
    "                best_match = result[0]\n",
    "                gesture_name = best_match\n",
    "                cv2.putText(frame, f\"Gesture: {gesture_name}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No gesture detected\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Gesture Recognition\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
