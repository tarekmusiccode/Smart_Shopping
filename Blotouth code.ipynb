{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\hciii course\\hciii\\.venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Device connected\n",
      "Connected to the webcam successfully\n",
      "10 encoding images found.\n",
      "Encoding images loaded\n",
      "Starting continuous scanning for Bluetooth devices (each scan lasts 5 seconds)...\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is neutral\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is neutral\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is neutral\n",
      "Message sent: Rawan is sad\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is neutral\n",
      "Message sent: Unknown is neutral\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is surprise\n",
      "Message sent: Rawan is neutral\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is happy\n",
      "Message sent: Rawan is happy\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is happy\n",
      "Message sent: Rawan is happy\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is neutral\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is happy\n",
      "Message sent: Rawan is neutral\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is neutral\n",
      "Message sent: Rawan is neutral\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is happy\n",
      "Message sent: Rawan is happy\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is happy\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Message sent: Rawan is neutral\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n",
      "Scanning for Bluetooth devices...\n",
      "No devices found during this scan.\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import pickle\n",
    "import threading\n",
    "from queue import Queue\n",
    "from dollarpy import Point\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "from simple_facerec import SimpleFacerec\n",
    "import pandas as pd\n",
    "import bluetooth\n",
    "import asyncio\n",
    "from openpyxl import load_workbook  # For Excel file manipulation\n",
    "import time\n",
    "\n",
    "HOSTNAME = '127.0.0.1'\n",
    "PORT = 5010\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_path = r\"C:\\Users\\alie0\\OneDrive\\Desktop\\to rokaia\\Smart_Shopping-main\\bloutooth.xlsx\"\n",
    "\n",
    "# Load registered MAC addresses from Excel\n",
    "try:\n",
    "    mac_df = pd.read_excel(excel_path)\n",
    "    registered_macs = set(mac_df['mac_address'].dropna().astype(str).tolist())\n",
    "except Exception as e:\n",
    "    print(\"Error reading Excel file:\", e)\n",
    "    registered_macs = set()  # Start with an empty set if thereâ€™s an issue\n",
    "\n",
    "# Socket setup\n",
    "soc = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "soc.bind((HOSTNAME, PORT))\n",
    "soc.listen(5)\n",
    "conn, addr = soc.accept()\n",
    "print(\"Device connected\")\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to connect to the webcam\")\n",
    "else:\n",
    "    print(\"Connected to the webcam successfully\")\n",
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO(r\"C:\\Users\\alie0\\OneDrive\\Desktop\\to rokaia\\Smart_Shopping-main\\best (2).pt\")\n",
    "target_class_names = [\"deodorant\", \"vitamin\"]\n",
    "target_classes = [index for index, name in model.names.items() if name in target_class_names]\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize face recognition\n",
    "sfr = SimpleFacerec()\n",
    "sfr.load_encoding_images(\"images/\")\n",
    "\n",
    "# Lock for thread synchronization\n",
    "camera_lock = threading.Lock()\n",
    "socket_lock = threading.Lock()\n",
    "\n",
    "# Frame queue for threads\n",
    "frame_queue = Queue(maxsize=10)\n",
    "\n",
    "# Shutdown flag\n",
    "shutdown_flag = False\n",
    "\n",
    "def send_data(msg, delay=2):\n",
    "    try:\n",
    "        with socket_lock:\n",
    "            if conn.fileno() != -1:\n",
    "                conn.send(msg)\n",
    "                print(f\"Message sent: {msg.decode('utf-8')}\")\n",
    "                time.sleep(delay)  # Introduce a delay between messages\n",
    "            else:\n",
    "                print(\"Socket is closed.\")\n",
    "    except socket.error as e:\n",
    "        print(f\"Socket error: {e}\")\n",
    "        global shutdown_flag\n",
    "        shutdown_flag = True\n",
    "        conn.close()\n",
    "\n",
    "def capture_frame():\n",
    "    global shutdown_flag\n",
    "    while not shutdown_flag:\n",
    "        with camera_lock:\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                if frame_queue.full():\n",
    "                    frame_queue.get()\n",
    "                frame_queue.put(frame)\n",
    "            else:\n",
    "                print(\"Failed to capture frame.\")\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "\n",
    "def capture_gestures():\n",
    "    global shutdown_flag  # Ensure we're modifying the global shutdown_flag\n",
    "    with open('gesture_recognizer1.pkl', 'rb') as file:\n",
    "        recognizer = pickle.load(file)\n",
    "    \n",
    "    points = []\n",
    "    while not shutdown_flag:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "\n",
    "            # Convert the frame to RGB for MediaPipe processing\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(frame_rgb)\n",
    "            annotated_image = frame.copy()\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    \n",
    "                    # Capture important hand landmarks for gesture recognition\n",
    "                    wrist = Point(hand_landmarks.landmark[0].x, hand_landmarks.landmark[0].y, 1)\n",
    "                    thumb_cmc = Point(hand_landmarks.landmark[1].x, hand_landmarks.landmark[1].y, 1)\n",
    "                    thumb_mcp = Point(hand_landmarks.landmark[2].x, hand_landmarks.landmark[2].y, 1)\n",
    "                    thumb_ip = Point(hand_landmarks.landmark[3].x, hand_landmarks.landmark[3].y, 1)\n",
    "                    thumb_tip = Point(hand_landmarks.landmark[4].x, hand_landmarks.landmark[4].y, 1)\n",
    "\n",
    "                    points = [wrist, thumb_cmc, thumb_mcp, thumb_ip, thumb_tip]\n",
    "\n",
    "                    print(f\"Hand landmarks: {points}\")  # Debug: Log the landmarks\n",
    "                    try:\n",
    "                        # Check if the recognizer is working and making a prediction\n",
    "                        prediction = recognizer.recognize(points)\n",
    "                        print(f\"Predictions: {prediction}\")  # Debugging\n",
    "                        \n",
    "                        if prediction and len(prediction) > 0:\n",
    "                            detected_gesture = prediction[0]\n",
    "                            print(f\"Detected gesture: {detected_gesture}\")  # Debugging\n",
    "                            msg_pred = f\"{detected_gesture}\".encode(\"utf-8\")\n",
    "                            if conn.fileno() != -1:  # Check if the connection is still open\n",
    "                                send_data(msg_pred)  # Send data to the client\n",
    "                            else:\n",
    "                                print(\"Connection closed, unable to send gesture data.\")\n",
    "                    except Exception as e:\n",
    "                        print(\"An error occurred:\", str(e))\n",
    "            else:\n",
    "                print(\"No hand landmarks detected.\")\n",
    "\n",
    "            # Display the annotated image with landmarks\n",
    "            cv2.imshow('Camera - Gesture Recognition', annotated_image)\n",
    "\n",
    "            # Exit if the 'q' key is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "#  face recongnition part \n",
    "excel_file_face = r\"C:\\Users\\alie0\\OneDrive\\Desktop\\to rokaia\\Smart_Shopping-main\\UserProfileByFace.xlsx\"\n",
    "columns = [\"Name\", \"quantity\", \"products\", \"emotion\"]\n",
    "# Check if the file exists; if not, create it\n",
    "try:\n",
    "    df = pd.read_excel(excel_file_face)\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df.to_excel(excel_file_face, index=False)\n",
    "def update_excel(name, emotion):\n",
    "    global df\n",
    "    # Check if the user already exists in the sheet\n",
    "    new_row = {\"Name\": name, \"quantity\": 1, \"products\": \"None\", \"emotion\": emotion}\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    df.to_excel(excel_file_face, index=False)\n",
    "def detect_face_and_emotions():\n",
    "    global shutdown_flag\n",
    "    while not shutdown_flag:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            flipped_frame = cv2.flip(frame, 1)\n",
    "            rgb_frame = cv2.cvtColor(flipped_frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations, face_names = sfr.detect_known_faces(flipped_frame)\n",
    "\n",
    "            for face_loc, name in zip(face_locations, face_names):\n",
    "                y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "                face_roi = rgb_frame[y1:y2, x1:x2]\n",
    "                try:\n",
    "                    emotion_result = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\n",
    "                    emotion = emotion_result[0]['dominant_emotion']\n",
    "                    update_excel(name, emotion)\n",
    "                except Exception as e:\n",
    "                    emotion = \"Unknown\"\n",
    "                \n",
    "                # Update the Excel sheet with the user's data\n",
    "                \n",
    "                \n",
    "                display_text = f\"{name} is {emotion}\"\n",
    "                send_data(display_text.encode(\"utf-8\"))\n",
    "                cv2.putText(flipped_frame, display_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 200), 2)\n",
    "                cv2.rectangle(flipped_frame, (x1, y1), (x2, y2), (0, 0, 200), 2)\n",
    "\n",
    "            cv2.imshow(\"Face Recognition and Emotion Detection\", flipped_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "\n",
    "def detect_objects():\n",
    "    global shutdown_flag\n",
    "    while not shutdown_flag:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            frame_resized = cv2.resize(frame, (640, 640))\n",
    "            results = model(frame_resized, conf=0.9, classes=target_classes)\n",
    "\n",
    "            annotated_frame = results[0].plot()\n",
    "            if len(results[0].boxes.cls) > 0:\n",
    "                for box, score, cls in zip(results[0].boxes.xywh, results[0].boxes.conf, results[0].boxes.cls):\n",
    "                    class_name = model.names[int(cls)]\n",
    "                    confidence = float(score)\n",
    "                    if class_name in target_class_names:\n",
    "                        msg_class = f\"Detected Object: {class_name}\".encode(\"utf-8\")\n",
    "                        send_data(msg_class)\n",
    "\n",
    "            cv2.imshow(\"Object Detection\", annotated_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "\n",
    "# Bluetooth function using asyncio\n",
    "\n",
    "async def continuous_bluetooth_login(scan_duration=3, cycles=1):\n",
    "    print(f\"Starting continuous scanning for Bluetooth devices (each scan lasts {scan_duration} seconds)...\")\n",
    "\n",
    "    try:\n",
    "        while True:  # Continuous scanning loop\n",
    "            print(\"Scanning for Bluetooth devices...\")\n",
    "            all_devices = []  # List to collect all devices detected in the current cycle\n",
    "\n",
    "            # Perform multiple scan cycles per round\n",
    "            for _ in range(cycles):\n",
    "                nearby_devices = bluetooth.discover_devices(\n",
    "                    duration=scan_duration, lookup_names=True, device_id=-1, flush_cache=True\n",
    "                )\n",
    "                for addr, name in nearby_devices:\n",
    "                    all_devices.append((addr, name))\n",
    "\n",
    "            # Remove duplicates based on MAC address\n",
    "            unique_devices = {device[0]: device[1] for device in all_devices}.items()\n",
    "\n",
    "            if not unique_devices:\n",
    "                print(\"No devices found during this scan.\")\n",
    "            else:\n",
    "                for mac_address, device_name in unique_devices:\n",
    "                    print(f\"Detected device: {device_name}, MAC Address: {mac_address}\")\n",
    "\n",
    "                    if mac_address in registered_macs:\n",
    "                        user_data = mac_df.loc[mac_df[\"mac_address\"] == mac_address]\n",
    "                        user = user_data.iloc[0]  # Get the matched user profile\n",
    "                        username = user['Name']\n",
    "                        role = user['role']\n",
    "\n",
    "                        # Format the message to send to the C# application\n",
    "                        msg = f\"{username} has successfully logged in. Role: {role}\".encode(\"utf-8\")\n",
    "                        send_data(msg)  # Send the message to the C# app via socket\n",
    "                        print(f\"Login successful for user: {username}, Role: {role}\")\n",
    "                    else:\n",
    "                        print(f\"Unregistered device detected: {mac_address} (Name: {device_name}).\")\n",
    "\n",
    "            await asyncio.sleep(5)  # Pause before the next scan cycle\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during Bluetooth scanning: {e}\")\n",
    "\n",
    "\n",
    "def scan_in_background():\n",
    "    try:\n",
    "        asyncio.run(continuous_bluetooth_login(scan_duration=5))\n",
    "    except RuntimeError as e:\n",
    "        if \"This event loop is already running\" in str(e):\n",
    "            asyncio.ensure_future(continuous_bluetooth_login(scan_duration=5))\n",
    "\n",
    "\n",
    "# Start threads\n",
    "camera_thread = threading.Thread(target=capture_frame)\n",
    "face_emotion_thread = threading.Thread(target=detect_face_and_emotions)\n",
    "gesture_thread = threading.Thread(target=capture_gestures)\n",
    "object_detection_thread = threading.Thread(target=detect_objects)\n",
    "scanner_thread = threading.Thread(target=scan_in_background)\n",
    "camera_thread.start()\n",
    "face_emotion_thread.start()\n",
    "gesture_thread.start()\n",
    "object_detection_thread.start()\n",
    "scanner_thread.start()\n",
    "camera_thread.join()\n",
    "face_emotion_thread.join()\n",
    "gesture_thread.join()\n",
    "object_detection_thread.join()\n",
    "scanner_thread.join()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "conn.send(bytes(\"q\", \"utf-8\"))\n",
    "conn.close()\n",
    "soc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device connected\n",
      "Connected to the webcam successfully\n",
      "10 encoding images found.\n",
      "Encoding images loaded\n",
      "Message sent: Detected Gesture: right\n",
      "Message sent: Detected Gesture: right\n",
      "Message sent: Detected Gesture: right\n",
      "Message sent: Detected Gesture: right\n",
      "Message sent: Detected Gesture: right\n",
      "Message sent: Detected Gesture: right\n",
      "Message sent: Detected Gesture: left\n",
      "Message sent: Detected Gesture: left\n",
      "Message sent: Detected Gesture: left\n",
      "Message sent: Detected Gesture: left\n",
      "Message sent: Detected Gesture: left\n",
      "Message sent: Detected Gesture: left\n",
      "Message sent: Detected Gesture: left\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import pickle\n",
    "import threading\n",
    "from queue import Queue\n",
    "from dollarpy import Recognizer, Template, Point  # Ensure Recognizer is imported\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "from simple_facerec import SimpleFacerec\n",
    "import pandas as pd\n",
    "import bluetooth\n",
    "import asyncio\n",
    "from openpyxl import load_workbook  # For Excel file manipulation\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "HOSTNAME = '127.0.0.1'\n",
    "PORT = 5010\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_path = r\"C:\\Users\\alie0\\OneDrive\\Desktop\\to rokaia\\Smart_Shopping-main\\bloutooth.xlsx\"\n",
    "\n",
    "# Load registered MAC addresses from Excel\n",
    "try:\n",
    "    mac_df = pd.read_excel(excel_path)\n",
    "    registered_macs = set(mac_df['mac_address'].dropna().astype(str).tolist())\n",
    "except Exception as e:\n",
    "    print(\"Error reading Excel file:\", e)\n",
    "    registered_macs = set()  # Start with an empty set if thereâ€™s an issue\n",
    "\n",
    "# Socket setup\n",
    "soc = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "soc.bind((HOSTNAME, PORT))\n",
    "soc.listen(5)\n",
    "conn, addr = soc.accept()\n",
    "print(\"Device connected\")\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to connect to the webcam\")\n",
    "else:\n",
    "    print(\"Connected to the webcam successfully\")\n",
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO(r\"C:\\Users\\alie0\\OneDrive\\Desktop\\to rokaia\\Smart_Shopping-main\\best (2).pt\")\n",
    "target_class_names = [\"deodorant\", \"vitamin\"]\n",
    "target_classes = [index for index, name in model.names.items() if name in target_class_names]\n",
    "\n",
    "# Initialize face recognition\n",
    "sfr = SimpleFacerec()\n",
    "sfr.load_encoding_images(\"images/\")\n",
    "\n",
    "# Lock for thread synchronization\n",
    "camera_lock = threading.Lock()\n",
    "socket_lock = threading.Lock()\n",
    "\n",
    "# Frame queue for threads\n",
    "frame_queue = Queue(maxsize=10)\n",
    "\n",
    "# Shutdown flag\n",
    "shutdown_flag = False\n",
    "\n",
    "def send_data(msg, delay=2):\n",
    "    try:\n",
    "        with socket_lock:\n",
    "            if conn.fileno() != -1:\n",
    "                conn.send(msg)\n",
    "                print(f\"Message sent: {msg.decode('utf-8')}\")\n",
    "                time.sleep(delay)  # Introduce a delay between messages\n",
    "            else:\n",
    "                print(\"Socket is closed.\")\n",
    "    except socket.error as e:\n",
    "        print(f\"Socket error: {e}\")\n",
    "        global shutdown_flag\n",
    "        shutdown_flag = True\n",
    "        conn.close()\n",
    "\n",
    "def capture_frame():\n",
    "    global shutdown_flag\n",
    "    while not shutdown_flag:\n",
    "        with camera_lock:\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                if frame_queue.full():\n",
    "                    frame_queue.get()\n",
    "                frame_queue.put(frame)\n",
    "            else:\n",
    "                print(\"Failed to capture frame.\")\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "\n",
    "def loadTemplates(save_path):\n",
    "    if os.path.exists(save_path):\n",
    "        with open(save_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return []\n",
    "\n",
    "def getPointsFromFrame(frame):\n",
    "    points = []\n",
    "\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Process hand landmarks\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    x, y = landmark.x, landmark.y\n",
    "                    if not (np.isnan(x) or np.isnan(y)):\n",
    "                        points.append(Point(x, y, stroke_id=0))\n",
    "    return points\n",
    "\n",
    "def capture_gestures():\n",
    "    global shutdown_flag  # Ensure we're modifying the global shutdown_flag\n",
    "\n",
    "    # Load gesture templates\n",
    "    template_file = \"gesture_templates2.pkl\"\n",
    "    templates = loadTemplates(template_file)\n",
    "\n",
    "    if not templates:\n",
    "        print(\"No templates loaded. Ensure the gesture_templates2.pkl file exists and contains valid data.\")\n",
    "        return\n",
    "\n",
    "    # Initialize Recognizer with loaded templates\n",
    "    recognizer = Recognizer(templates)\n",
    "\n",
    "    with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "        while not shutdown_flag:\n",
    "            if not frame_queue.empty():\n",
    "                frame = frame_queue.get()\n",
    "\n",
    "                # Process frame for hand landmarks\n",
    "                points = getPointsFromFrame(frame)\n",
    "                x_values = [p.x for p in points]\n",
    "                y_values = [p.y for p in points]\n",
    "\n",
    "                if points and (max(x_values) - min(x_values) != 0) and (max(y_values) - min(y_values) != 0):\n",
    "                    try:\n",
    "                        # Recognize gesture\n",
    "                        result = recognizer.recognize(points)\n",
    "\n",
    "                        if result:\n",
    "                            best_match = result[0]\n",
    "                            gesture_name = best_match\n",
    "\n",
    "                            # Display detected gesture on the frame\n",
    "                            cv2.putText(frame, f\"Gesture: {gesture_name}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                            # Send detected gesture via socket\n",
    "                            msg_pred = f\"Detected Gesture: {gesture_name}\".encode(\"utf-8\")\n",
    "                            if conn.fileno() != -1:  # Check if the connection is still open\n",
    "                                send_data(msg_pred)\n",
    "                            else:\n",
    "                                print(\"Connection closed, unable to send gesture data.\")\n",
    "                    except Exception as e:\n",
    "                        print(\"An error occurred during gesture recognition:\", str(e))\n",
    "                else:\n",
    "                    cv2.putText(frame, \"No gesture detected\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "                # Display the frame with annotations\n",
    "                cv2.imshow(\"Gesture Recognition\", frame)\n",
    "\n",
    "                # Exit if the 'q' key is pressed\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    shutdown_flag = True\n",
    "                    break\n",
    "excel_file_face = r\"C:\\Users\\alie0\\OneDrive\\Desktop\\to rokaia\\Smart_Shopping-main\\UserProfileByFace.xlsx\"\n",
    "columns = [\"Name\", \"quantity\", \"products\", \"emotion\"]\n",
    "# Check if the file exists; if not, create it\n",
    "try:\n",
    "    df = pd.read_excel(excel_file_face)\n",
    "except FileNotFoundError:\n",
    "    df = pd.DataFrame(columns=columns)\n",
    "    df.to_excel(excel_file_face, index=False)\n",
    "def update_excel(name, emotion):\n",
    "    global df\n",
    "    # Check if the user already exists in the sheet\n",
    "    new_row = {\"Name\": name, \"quantity\": 1, \"products\": \"None\", \"emotion\": emotion}\n",
    "    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "    df.to_excel(excel_file_face, index=False)\n",
    "def detect_face_and_emotions():\n",
    "    global shutdown_flag\n",
    "    while not shutdown_flag:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            flipped_frame = cv2.flip(frame, 1)\n",
    "            rgb_frame = cv2.cvtColor(flipped_frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations, face_names = sfr.detect_known_faces(flipped_frame)\n",
    "\n",
    "            for face_loc, name in zip(face_locations, face_names):\n",
    "                y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "                face_roi = rgb_frame[y1:y2, x1:x2]\n",
    "                try:\n",
    "                    emotion_result = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\n",
    "                    emotion = emotion_result[0]['dominant_emotion']\n",
    "                    update_excel(name, emotion)\n",
    "                except Exception as e:\n",
    "                    emotion = \"Unknown\"\n",
    "                \n",
    "                # Update the Excel sheet with the user's data\n",
    "                \n",
    "                \n",
    "                display_text = f\"{name} is {emotion}\"\n",
    "                send_data(display_text.encode(\"utf-8\"))\n",
    "                cv2.putText(flipped_frame, display_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 200), 2)\n",
    "                cv2.rectangle(flipped_frame, (x1, y1), (x2, y2), (0, 0, 200), 2)\n",
    "\n",
    "            cv2.imshow(\"Face Recognition and Emotion Detection\", flipped_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "\n",
    "def detect_objects():\n",
    "    global shutdown_flag\n",
    "    while not shutdown_flag:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            frame_resized = cv2.resize(frame, (640, 640))\n",
    "            results = model(frame_resized, conf=0.9, classes=target_classes)\n",
    "\n",
    "            annotated_frame = results[0].plot()\n",
    "            if len(results[0].boxes.cls) > 0:\n",
    "                for box, score, cls in zip(results[0].boxes.xywh, results[0].boxes.conf, results[0].boxes.cls):\n",
    "                    class_name = model.names[int(cls)]\n",
    "                    confidence = float(score)\n",
    "                    if class_name in target_class_names:\n",
    "                        msg_class = f\"Detected Object: {class_name}\".encode(\"utf-8\")\n",
    "                        send_data(msg_class)\n",
    "\n",
    "            cv2.imshow(\"Object Detection\", annotated_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "\n",
    "# Bluetooth function using asyncio\n",
    "\n",
    "async def continuous_bluetooth_login(scan_duration=3, cycles=1):\n",
    "    print(f\"Starting continuous scanning for Bluetooth devices (each scan lasts {scan_duration} seconds)...\")\n",
    "\n",
    "    try:\n",
    "        while True:  # Continuous scanning loop\n",
    "            print(\"Scanning for Bluetooth devices...\")\n",
    "            all_devices = []  # List to collect all devices detected in the current cycle\n",
    "\n",
    "            # Perform multiple scan cycles per round\n",
    "            for _ in range(cycles):\n",
    "                nearby_devices = bluetooth.discover_devices(\n",
    "                    duration=scan_duration, lookup_names=True, device_id=-1, flush_cache=True\n",
    "                )\n",
    "                for addr, name in nearby_devices:\n",
    "                    all_devices.append((addr, name))\n",
    "\n",
    "            # Remove duplicates based on MAC address\n",
    "            unique_devices = {device[0]: device[1] for device in all_devices}.items()\n",
    "\n",
    "            if not unique_devices:\n",
    "                print(\"No devices found during this scan.\")\n",
    "            else:\n",
    "                for mac_address, device_name in unique_devices:\n",
    "                    print(f\"Detected device: {device_name}, MAC Address: {mac_address}\")\n",
    "\n",
    "                    if mac_address in registered_macs:\n",
    "                        user_data = mac_df.loc[mac_df[\"mac_address\"] == mac_address]\n",
    "                        user = user_data.iloc[0]  # Get the matched user profile\n",
    "                        username = user['Name']\n",
    "                        role = user['role']\n",
    "\n",
    "                        # Format the message to send to the C# application\n",
    "                        msg = f\"{username} has successfully logged in. Role: {role}\".encode(\"utf-8\")\n",
    "                        send_data(msg)  # Send the message to the C# app via socket\n",
    "                        print(f\"Login successful for user: {username}, Role: {role}\")\n",
    "                    else:\n",
    "                        print(f\"Unregistered device detected: {mac_address} (Name: {device_name}).\")\n",
    "\n",
    "            await asyncio.sleep(5)  # Pause before the next scan cycle\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during Bluetooth scanning: {e}\")\n",
    "\n",
    "\n",
    "def scan_in_background():\n",
    "    try:\n",
    "        asyncio.run(continuous_bluetooth_login(scan_duration=5))\n",
    "    except RuntimeError as e:\n",
    "        if \"This event loop is already running\" in str(e):\n",
    "            asyncio.ensure_future(continuous_bluetooth_login(scan_duration=5))\n",
    "\n",
    "\n",
    "# Start threads\n",
    "camera_thread = threading.Thread(target=capture_frame)\n",
    "#face_emotion_thread = threading.Thread(target=detect_face_and_emotions)\n",
    "gesture_thread = threading.Thread(target=capture_gestures)\n",
    "#object_detection_thread = threading.Thread(target=detect_objects)\n",
    "#scanner_thread = threading.Thread(target=scan_in_background)\n",
    "camera_thread.start()\n",
    "#face_emotion_thread.start()\n",
    "gesture_thread.start()\n",
    "#object_detection_thread.start()\n",
    "#scanner_thread.start()\n",
    "#camera_thread.join()\n",
    "#face_emotion_thread.join()\n",
    "gesture_thread.join()\n",
    "#object_detection_thread.join()\n",
    "#scanner_thread.join()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "conn.send(bytes(\"q\", \"utf-8\"))\n",
    "conn.close()\n",
    "soc.close()\n",
    "# The rest of the face recognition, object detection, and Bluetooth scanning functions remain unchanged\n",
    "# Add the necessary threading and thread join logic as shown in the original script\n",
    "\n",
    "# Start threads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
