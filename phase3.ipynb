{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import cv2\n",
    "import pickle\n",
    "import threading\n",
    "from queue import Queue\n",
    "from dollarpy import Point\n",
    "import mediapipe as mp\n",
    "from ultralytics import YOLO\n",
    "from deepface import DeepFace\n",
    "from simple_facerec import SimpleFacerec\n",
    "import pandas as pd\n",
    "import bluetooth\n",
    "import asyncio\n",
    "from openpyxl import load_workbook  # For Excel file manipulation\n",
    "import time\n",
    "\n",
    "HOSTNAME = '127.0.0.1'\n",
    "PORT = 5010\n",
    "\n",
    "# Path to the Excel file\n",
    "excel_path = \"bloutooth.xlsx\"\n",
    "\n",
    "# Load registered MAC addresses from Excel\n",
    "try:\n",
    "    mac_df = pd.read_excel(excel_path)\n",
    "    registered_macs = set(mac_df['mac_address'].dropna().astype(str).tolist())\n",
    "except Exception as e:\n",
    "    print(\"Error reading Excel file:\", e)\n",
    "    registered_macs = set()  # Start with an empty set if thereâ€™s an issue\n",
    "\n",
    "# Socket setup\n",
    "soc = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "soc.bind((HOSTNAME, PORT))\n",
    "soc.listen(5)\n",
    "conn, addr = soc.accept()\n",
    "print(\"Device connected\")\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video device.\")\n",
    "    exit(1)\n",
    "else:\n",
    "    print(\"Camera successfully opened.\")\n",
    "\n",
    "# Initialize YOLO model\n",
    "model = YOLO(r\"C:\\Users\\Lenovo\\Desktop\\hciii\\Smart_Shopping-main\\best (2).pt\")\n",
    "target_class_names = [\"deodorant\", \"vitamin\"]\n",
    "target_classes = [index for index, name in model.names.items() if name in target_class_names]\n",
    "\n",
    "# Initialize MediaPipe Hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "# Initialize face recognition\n",
    "sfr = SimpleFacerec()\n",
    "sfr.load_encoding_images(\"images/\")\n",
    "\n",
    "# Lock for thread synchronization\n",
    "camera_lock = threading.Lock()\n",
    "socket_lock = threading.Lock()\n",
    "\n",
    "# Frame queue for threads\n",
    "frame_queue = Queue(maxsize=10)\n",
    "\n",
    "# Shutdown flag\n",
    "shutdown_flag = False\n",
    "\n",
    "# Send data to the socket with delay\n",
    "def send_data(msg, delay=5):\n",
    "    try:\n",
    "        with socket_lock:\n",
    "            if conn.fileno() != -1:\n",
    "                conn.send(msg)\n",
    "                print(f\"Message sent: {msg.decode('utf-8')}\")\n",
    "                time.sleep(delay)  # Introduce a delay between messages (maximized delay)\n",
    "            else:\n",
    "                print(\"Socket is closed.\")\n",
    "    except socket.error as e:\n",
    "        print(f\"Socket error: {e}\")\n",
    "        global shutdown_flag\n",
    "        shutdown_flag = True\n",
    "        conn.close()\n",
    "\n",
    "# Capture video frames\n",
    "def capture_frame():\n",
    "    global shutdown_flag\n",
    "    while not shutdown_flag:\n",
    "        with camera_lock:\n",
    "            ret, frame = cap.read()\n",
    "            if ret:\n",
    "                if frame_queue.full():\n",
    "                    frame_queue.get()\n",
    "                frame_queue.put(frame)\n",
    "            else:\n",
    "                print(\"Failed to capture frame.\")\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "\n",
    "# Gesture recognition\n",
    "def capture_gestures():\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands()\n",
    "    with open('gesture_recognizer1.pkl', 'rb') as file:\n",
    "        recognizer = pickle.load(file)\n",
    "    points = []\n",
    "    wrist = [] #0\n",
    "    thumb_cmc = [] #1\n",
    "    thumb_mcp = [] #2\n",
    "    thumb_ip = [] #3\n",
    "    thumb_tip = [] #4\n",
    "    index_finger_mcp = [] #5\n",
    "    index_finger_pip = [] #6\n",
    "    index_finger_dip = [] #7\n",
    "    index_finger_tip = [] #8\n",
    "    middle_finger_mcp = [] #9\n",
    "    middle_finger_pip = [] #10\n",
    "    middle_finger_dip = [] #11\n",
    "    middle_finger_tip = [] #12\n",
    "    ring_finger_mcp = [] #13\n",
    "    ring_finger_pip = [] #14\n",
    "    ring_finger_dip = [] #15\n",
    "    ring_finger_tip = [] #16\n",
    "    pinky_mcp = [] #17 \n",
    "    pinky_pip = [] #18\n",
    "    pinky_dip = [] #19\n",
    "    pinky_tip = [] #20\n",
    "    frame_count = 1\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        _, frame = cap.read()\n",
    "        try:\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            results = hands.process(frame_rgb)\n",
    "            annotated_image = frame.copy()\n",
    "            \n",
    "            if results.multi_hand_landmarks:\n",
    "                for hand_landmarks in results.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    try:\n",
    "                        wrist.append(Point(hand_landmarks.landmark[0].x, hand_landmarks.landmark[0].y, 1))\n",
    "                        thumb_cmc.append(Point(hand_landmarks.landmark[1].x, hand_landmarks.landmark[1].y, 1))\n",
    "                        thumb_mcp.append(Point(hand_landmarks.landmark[2].x, hand_landmarks.landmark[2].y, 1))\n",
    "                        thumb_ip.append(Point(hand_landmarks.landmark[3].x, hand_landmarks.landmark[3].y, 1))\n",
    "                        thumb_tip.append(Point(hand_landmarks.landmark[4].x, hand_landmarks.landmark[4].y, 1))\n",
    "                        index_finger_mcp.append(Point(hand_landmarks.landmark[5].x, hand_landmarks.landmark[5].y, 1))\n",
    "                        index_finger_pip.append(Point(hand_landmarks.landmark[6].x, hand_landmarks.landmark[6].y, 1))\n",
    "                        index_finger_dip.append(Point(hand_landmarks.landmark[7].x, hand_landmarks.landmark[7].y, 1))\n",
    "                        index_finger_tip.append(Point(hand_landmarks.landmark[8].x, hand_landmarks.landmark[8].y, 1))\n",
    "                        middle_finger_mcp.append(Point(hand_landmarks.landmark[9].x, hand_landmarks.landmark[9].y, 1))\n",
    "                        middle_finger_pip.append(Point(hand_landmarks.landmark[10].x, hand_landmarks.landmark[10].y, 1))\n",
    "                        middle_finger_dip.append(Point(hand_landmarks.landmark[11].x, hand_landmarks.landmark[11].y, 1))\n",
    "                        middle_finger_tip.append(Point(hand_landmarks.landmark[12].x, hand_landmarks.landmark[12].y, 1))\n",
    "                        ring_finger_mcp.append(Point(hand_landmarks.landmark[13].x, hand_landmarks.landmark[13].y, 1))\n",
    "                        ring_finger_pip.append(Point(hand_landmarks.landmark[14].x, hand_landmarks.landmark[14].y, 1))\n",
    "                        ring_finger_dip.append(Point(hand_landmarks.landmark[15].x, hand_landmarks.landmark[15].y, 1))\n",
    "                        ring_finger_tip.append(Point(hand_landmarks.landmark[16].x, hand_landmarks.landmark[16].y, 1))\n",
    "                        pinky_mcp.append(Point(hand_landmarks.landmark[17].x, hand_landmarks.landmark[17].y, 1))\n",
    "                        pinky_pip.append(Point(hand_landmarks.landmark[18].x, hand_landmarks.landmark[18].y, 1))\n",
    "                        pinky_dip.append(Point(hand_landmarks.landmark[19].x, hand_landmarks.landmark[19].y, 1))\n",
    "                        pinky_tip.append(Point(hand_landmarks.landmark[20].x, hand_landmarks.landmark[20].y, 1))\n",
    "                        \n",
    "                        points = wrist + thumb_cmc + thumb_mcp + thumb_ip + thumb_tip + \\\n",
    "                            index_finger_mcp + index_finger_pip + index_finger_dip + index_finger_tip + \\\n",
    "                                middle_finger_mcp + middle_finger_pip + middle_finger_dip + middle_finger_tip + \\\n",
    "                                    ring_finger_mcp + ring_finger_pip + ring_finger_dip + ring_finger_tip + \\\n",
    "                                        pinky_mcp + pinky_pip + pinky_dip + pinky_tip\n",
    "                    except Exception as e:\n",
    "                        print(\"An error occurred:\", str(e))\n",
    "            frame_count += 1\n",
    "            if frame_count == 60:\n",
    "                frame_count = 0\n",
    "                try:\n",
    "                    prediction = recognizer.recognize(points)[0]\n",
    "                    print(prediction)\n",
    "                    if prediction:\n",
    "                        msg_pred = f\"{prediction}\".encode(\"utf-8\")\n",
    "                        conn.send(msg_pred)\n",
    "                except Exception as e:\n",
    "                    print(\"An error occurred:\", str(e))\n",
    "                cv2.imshow('Output 2', annotated_image)\n",
    "                points.clear()\n",
    "            annotated_image = cv2.resize(annotated_image, (700, 500))\n",
    "            cv2.imshow('Output', annotated_image)\n",
    "        except:\n",
    "            break\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            cv2.waitKey(100)\n",
    "            break\n",
    "\n",
    "# Detect faces and emotions\n",
    "def detect_face_and_emotions():\n",
    "    global shutdown_flag\n",
    "    while not shutdown_flag:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            flipped_frame = cv2.flip(frame, 1)\n",
    "            rgb_frame = cv2.cvtColor(flipped_frame, cv2.COLOR_BGR2RGB)\n",
    "            face_locations, face_names = sfr.detect_known_faces(flipped_frame)\n",
    "\n",
    "            for face_loc, name in zip(face_locations, face_names):\n",
    "                y1, x2, y2, x1 = face_loc[0], face_loc[1], face_loc[2], face_loc[3]\n",
    "                face_roi = rgb_frame[y1:y2, x1:x2]\n",
    "                try:\n",
    "                    emotion_result = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\n",
    "                    emotion = emotion_result[0]['dominant_emotion']\n",
    "                except Exception as e:\n",
    "                    emotion = \"Unknown\"\n",
    "                display_text = f\"{name} is {emotion}\"\n",
    "                cv2.putText(flipped_frame, display_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 200), 2)\n",
    "                cv2.rectangle(flipped_frame, (x1, y1), (x2, y2), (0, 0, 200), 2)\n",
    "\n",
    "                # Send message with a delay\n",
    "                msg_face_emotion = f\"{name} is {emotion}\".encode(\"utf-8\")\n",
    "                if conn.fileno() != -1:\n",
    "                    send_data(msg_face_emotion, delay=5)  # 5-second delay between messages\n",
    "\n",
    "            cv2.imshow(\"Face Recognition and Emotion Detection\", flipped_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "\n",
    "# Detect objects\n",
    "def detect_objects():\n",
    "    global shutdown_flag\n",
    "    while not shutdown_flag:\n",
    "        if not frame_queue.empty():\n",
    "            frame = frame_queue.get()\n",
    "            frame_resized = cv2.resize(frame, (640, 640))\n",
    "            results = model(frame_resized, conf=0.80, classes=target_classes)\n",
    "\n",
    "            annotated_frame = results[0].plot()\n",
    "            if len(results[0].boxes.cls) > 0:\n",
    "                for box, score, cls in zip(results[0].boxes.xywh, results[0].boxes.conf, results[0].boxes.cls):\n",
    "                    class_name = model.names[int(cls)]\n",
    "                    confidence = float(score)\n",
    "                    if class_name in target_class_names:\n",
    "                        msg_class = f\"Detected Object: {class_name}\".encode(\"utf-8\")\n",
    "                        send_data(msg_class, delay=5)  # 5-second delay between object detection messages\n",
    "\n",
    "            cv2.imshow(\"Object Detection\", annotated_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                shutdown_flag = True\n",
    "                break\n",
    "\n",
    "# Bluetooth function using asyncio\n",
    "\n",
    "async def continuous_bluetooth_login(scan_duration=3, cycles=1):\n",
    "    print(f\"Starting continuous scanning for Bluetooth devices (each scan lasts {scan_duration} seconds)...\")\n",
    "\n",
    "    try:\n",
    "        while True:  # Infinite loop to keep scanning continuously\n",
    "            nearby_devices = bluetooth.discover_devices(duration=scan_duration, lookup_names=True, lookup_uuids=True)\n",
    "            for addr, name in nearby_devices:\n",
    "                if addr in registered_macs:\n",
    "                    print(f\"Device {name} ({addr}) found and already registered.\")\n",
    "                    msg_bluetooth = f\"Device {name} ({addr}) is registered.\".encode(\"utf-8\")\n",
    "                    send_data(msg_bluetooth, delay=5)\n",
    "                else:\n",
    "                    print(f\"New device found: {name} ({addr}) - Not registered.\")\n",
    "            time.sleep(5)  # 5 seconds delay between each scan\n",
    "            cycles -= 1\n",
    "            if cycles == 0:\n",
    "                break\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Bluetooth scanning stopped manually.\")\n",
    "\n",
    "def scan_in_background():\n",
    "    try:\n",
    "        asyncio.run(continuous_bluetooth_login(scan_duration=5))\n",
    "    except RuntimeError as e:\n",
    "        if \"This event loop is already running\" in str(e):\n",
    "            asyncio.ensure_future(continuous_bluetooth_login(scan_duration=5))\n",
    "\n",
    "# Start threads\n",
    "camera_thread = threading.Thread(target=capture_frame)\n",
    "face_emotion_thread = threading.Thread(target=detect_face_and_emotions)\n",
    "gesture_thread = threading.Thread(target=capture_gestures)\n",
    "object_detection_thread = threading.Thread(target=detect_objects)\n",
    "scanner_thread = threading.Thread(target=scan_in_background)\n",
    "\n",
    "camera_thread.start()\n",
    "face_emotion_thread.start()\n",
    "gesture_thread.start()\n",
    "object_detection_thread.start()\n",
    "scanner_thread.start()\n",
    "\n",
    "camera_thread.join()\n",
    "face_emotion_thread.join()\n",
    "gesture_thread.join()\n",
    "object_detection_thread.join()\n",
    "scanner_thread.join()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "conn.send(bytes(\"q\", \"utf-8\"))\n",
    "conn.close()\n",
    "soc.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
